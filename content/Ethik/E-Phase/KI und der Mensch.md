---
quickshare-date: N/A
quickshare-url: Removed
---
Philosophie E-Phase (Hohmann)
Was ist der Mensch? – Einführung in die philosophische Anthropologie
***

**Nichts an diesem Bild ist Realität – noch nicht: Zwei künstliche Intelligenzen philosophieren in klassischen Posen darüber, wohin sie die technische Entwicklung geführt hat. (Bild: IMAGO IMAGES)**

**Künstliche Intelligenz** (**KI**), auch **artifizielle Intelligenz** (**AI**), 

[englisch ](https://de.wikipedia.org/wiki/Englische_Sprache)*artificial intelligence*, ist ein Teilgebiet der [Informatik,](https://de.wikipedia.org/wiki/Informatik) das sich mit der [Automatisierung](https://de.wikipedia.org/wiki/Automatisierung)intelligenten Verhaltens und dem [maschinellen Lernen](https://de.wikipedia.org/wiki/Maschinelles_Lernen) befasst. Der Begriff ist schwierig zu definieren, da es bereits an einer genauen[ Definition ](https://de.wikipedia.org/wiki/Definition)von [„Intelligenz“](https://de.wikipedia.org/wiki/Intelligenz) mangelt. Dennoch wird er in[ Forschung ](https://de.wikipedia.org/wiki/Forschung)und Entwicklung verwendet. 

Meist bezeichnet *künstliche Intelligenz* den Versuch, bestimmte Entscheidungsstrukturen des Menschen nachzubilden, indem z. B. ein[ Computer ](https://de.wikipedia.org/wiki/Computer)so gebaut und programmiert wird, dass er relativ eigenständig Probleme bearbeiten kann. Oftmals wird damit aber auch eine nachgeahmte Intelligenz bezeichnet, wobei durch größtenteils einfache[ Algorithmen ](https://de.wikipedia.org/wiki/Algorithmus)ein „intelligentes[ Verhalten“](https://de.wikipedia.org/wiki/Verhalten_\(Psychologie\)) simuliert werden soll, etwa bei [Computergegnern ](https://de.wikipedia.org/wiki/Computergegner)in [Computerspielen.](https://de.wikipedia.org/wiki/Computerspiel) 

Man unterscheidet zwischen starker und schwacher KI: *Starke KI* wären Computersysteme, die auf Augenhöhe mit Menschen die [Arbeit ](https://de.wikipedia.org/wiki/Arbeit_\(Philosophie\)#Aufhebung_des_Arbeitsbegriffs_seit_Mitte_des_20._Jahrhunderts)zur Erledigung schwieriger Aufgaben übernehmen können. Demgegenüber geht es bei *schwacher KI* darum, konkrete Anwendungsprobleme zu meistern. Das menschliche Denken und technische Anwendungen sollen hier in Einzelbereichen unterstützt werden. Die Fähigkeit zu lernen ist eine Hauptanforderung an KI-Systeme und muss ein integraler Bestandteil sein, der *nicht erst nachträglich* hinzugefügt werden darf. Ein zweites Hauptkriterium ist die Fähigkeit eines KI-Systems, mit Unsicherheit und [probabilistischen ](https://de.wikipedia.org/wiki/Probabilistisch)(die Wahrscheinlichkeit berücksichtigenden) Informationen umzugehen. Insbesondere sind solche Anwendungen von Interesse, zu deren Lösung nach allgemeinem Verständnis eine Form von „Intelligenz“ notwendig zu sein scheint. Letztlich geht es der schwachen KI somit um die **Simulation intelligenten Verhaltens** mit Mitteln der Mathematik und der Informatik, es geht ihr nicht um **Schaffung von[ Bewusstsein](https://de.wikipedia.org/wiki/Bewusstsein) oder um ein tieferes Ver- ständnis von Intelligenz**. Während die Schaffung starker KI an ihrer[ philosophischen ](https://de.wikipedia.org/wiki/Philosophie)Fragestellung bis heute scheiterte, sind auf der Seite der schwachen KI in den letzten Jahren bedeutende Fortschritte erzielt worden. 

Ein starkes KI-System muss nicht viele Gemeinsamkeiten mit dem Menschen haben. Es wird wahrscheinlich eine andersartige kognitive Architektur aufweisen und in seinen Entwicklungsstadien ebenfalls nicht mit den evolutionären kognitiven Stadien des menschlichen Denkens vergleichbar sein. Vor allem ist nicht anzunehmen, dass eine künstliche Intelligenz Gefühle wie Liebe, Hass, Angst oder Freude besitzt. 

## **Sprachmodelle** (Chat-GPT) 

Künstliche Intelligenzen, die Text verstehen und erzeugen, werden Sprachmodelle genannt, weil sie mathematische Regeln in menschlicher Sprache erkennen. Systeme wie GPT-4 von OpenAI berechnen im Wesentlichen, welche Wörter statistisch häufig zusammenstehen. Dabei kommen plausible Texte heraus, die aber nicht immer inhaltlich korrekt sind. Textgeneratoren können im Alltag nützlich sein, etwa um E-Mails zu verfassen. Sprachmodelle könnten Zeitungsarchive oder ganze Bibliotheken durchforsten und Menschen dabei helfen, darin zu finden, was sie suchen. Doch es ist auch möglich, dass sie missbraucht werden, zum Beispiel um Betrugsmails zu verfassen. 

Die Technik wird rasant weiterentwickelt. Es gibt bereits sogenannte multimodale Sprachmodelle, die nicht nur Sprache, sondern auch Bilder oder Videos verarbeiten. 

Manche Forscher meinen, die Systeme würden sich bei der Analyse unserer Sprache eine Art Modell der Welt erarbeiten. Ob man dabei von Verständnis sprechen kann, ist eine Frage der Interpretation. Einige Microsoft-Wissenschaftler veröffentlichten im März 2023 eine Studie, in der sie schreiben, „Funken von Intelligenz“ bei GPT-4 beobachtet zu haben. 

## **Der Turing-Test** 

Mit dem später sogenannten **Turing-Test** formulierte [Alan Turing](https://de.wikipedia.org/wiki/Alan_Turing![](attachments/Aspose.Words.a83ed5ee-2a1e-4067-b1d2-28352a618d27.003.png))im Jahr 1950 eine Idee, wie man feststellen könnte, ob ein [Computer,](https://de.wikipedia.org/wiki/Computer) also eine Maschine, ein dem [Menschen](https://de.wikipedia.org/wiki/Mensch) gleichwertiges [Denkvermögen](https://de.wikipedia.org/wiki/Denkverm%C3%B6gen) hätte.

Er selber nannte diesen Test ursprünglich „*imitation game*“, was zunächst nur eine theoretische Skizze war. Sie wurde erst später genauer und konkreter ausformuliert (nach Turings Suizid 1954), nachdem die [künstliche Intelligenz](https://de.wikipedia.org/wiki/K%C3%BCnstliche_Intelligenz) als Teilbereich der [Informatik](https://de.wikipedia.org/wiki/Informatik) zu einem eigenständigen akademischen Fachgebiet geworden war. Seither ist dieser Test in der Diskussion über künstliche Intelligenz in aller Munde und dient immer wieder dazu, den[ Mythos ](https://de.wikipedia.org/wiki/Mythos)von der denkenden Maschine für das [Computerzeitalter](https://de.wikipedia.org/wiki/Computerzeitalter) neu zu beleben. 

## **Die Robotergesetze nach Asimov** 

Der Science-Fiktion-Autor Isaac Asimov setzte sich in seinen literarischen Werken mit der Beziehung zwischen dem Menschen und Robotern auseinander und formulierte in seiner Kurz-Geschichte *Runaround* (1942) erstmalig seine sogenannten ***Robotergesetze***. 

In ihrer ursprünglichen Form lauten sie folgendermaßen: 

1. Ein Roboter darf keinem Wesen Schaden zufügen oder durch Untätigkeit zulassen, dass einem menschlichen Wesen Schaden zugefügt wird. 
1. Ein Roboter muss den Befehlen gehorchen, die ihm vom Menschen erteilt werden, es sei denn, dies würde gegen das erste Gesetz verstoßen. 
1. Ein Roboter muss seine eigene Existenz schützen, solange solch ein Schutz nicht gegen das erste oder zweite Gesetz verstößt. 

Im Jahr 1983 erweitere Asimov diesen hierarchischen Kodex um ein weiteres, das sog. nullte Robotergesetz, das er als übergeordneten Grundsatz den anderen Regeln voranstellte: 0. Ein Roboter darf der Menschheit keinen Schaden zufügen oder durch Untätigkeit zulassen, dass der Menschheit Schaden zugefügt wird. 
